# -*- coding: utf-8 -*-
"""SnowNLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SXNLHNXttYplFV0nzY63cUXkQu8I92U0
"""

import pandas as pd
import numpy as np
!pip install snownlp
from snownlp import SnowNLP

filename = 'tsmc-2'
df = pd.read_csv(filename+'.csv', encoding='utf-8', parse_dates=True)
# df['date'] = df['日期']+'/2020'
df = df.drop(columns = ['Unnamed: 0'])
# df = df.drop(columns = ['日期'])
# df['date']= pd.to_datetime(df['date']) 
# df = df.sort_values(by='date')
# df['標題'] = df['標題'].str.strip('Re: ')

content = df['標題']
s_list = []
for topic in  content: 
  s=SnowNLP(topic)
  senti = s.sentiments
  s_list.append(senti)
df['sentiments'] = s_list

df.to_csv(filename+'_snownlp.csv',index=False, encoding='utf-8-sig')
df

# idx = pd.date_range('2020-01-01', '2020-12-31')
# df_senti_average = df.groupby('date').sentiments.mean()
# df_features = pd.DataFrame()
# df_features['sentiments'] = df_senti_average
# # df_features['subjects'] = subject_count
# df_features.index = pd.DatetimeIndex(df_features.index)
# df_features = df_features.reindex(idx, fill_value=0)
# df_features

# subject_count.index = pd.DatetimeIndex(subject_count.index)
# subject_count = subject_count.reindex(idx, fill_value=0)
# df_features['subjects'] = subject_count
# df_features = df_features.reset_index()

# zero_idx = np.where(df_features['sentiments'] == 0)
# zero_idx[0][0]
# for idx in zero_idx[0]:
#   # print(idx)
#   df_features.iloc[idx] = df_features.iloc[idx-1]

# df_features.to_csv('TSMC_snownlp.csv',index=False)

